# spark-log-processor
A tool built with SparkSQL and HIVE to derive some performance metrics from the log files generated by spark. 

## Usage
To generate log files from Spark you should add the following properties to your spark-defaults.conf:
* `spark.eventLog.enabled true`
* `spark.eventLog.dir file://some/directory/of/your/choiche`

Note that the spark event log directory can also be on another file system like hdfs (e.g. hdfs://user/logs)
In order to build the DAG from from the logs the latest development versionof Spark (1.4.0.snaphot) should be used.

The tool accepts 3 parameters:
* the path to the log file `-i --inputFile`
* the path to the output folder `-o --outputFile`
* the optional flag `-l` can be used to run the tool in a local instance of spark istead of using a cluster

Once built has been built can be invoked by using spark-submit script

## Build
The tool can be built using Maven with
`mvn clean package`

it will generate a fat jar with all the needed dependencies
