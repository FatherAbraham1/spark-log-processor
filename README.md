# spark-log-processor
A tool built with SparkSQL and HIVE to derive some performance metrics from the log files generated by spark. 
In order to use the tool you need a version of Spark that include support for Hive. To include such support in your spark build blease look at the [Spark build documentation](https://spark.apache.org/docs/latest/building-spark.html#building-with-hive-and-jdbc-support)


## Usage
To generate log files from Spark you should add the following properties to your spark-defaults.conf:
* `spark.eventLog.enabled true`
* `spark.eventLog.dir file://some/directory/of/your/choiche`

Note that the spark event log directory can also be on another file system like hdfs (e.g. hdfs://user/logs)
In order to build the DAG from from the logs the latest development versionof Spark (1.4.0.snaphot) should be used.

Use parameter `-u --usage` to show the Usage Guide

Once built has been built can be invoked by using spark-submit script available in spark

## Build
The tool can be built using Maven with

`mvn clean package`

it will generate a fat jar with all the needed dependencies
