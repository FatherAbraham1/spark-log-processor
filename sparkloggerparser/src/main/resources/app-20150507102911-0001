{"Event":"SparkListenerLogStart","Spark Version":"1.4.0-SNAPSHOT"}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"192.168.230.130","Port":60487},"Maximum Memory":278302556,"Timestamp":1431008951324}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/usr/lib/jvm/java-7-oracle/jre","Java Version":"1.7.0_80 (Oracle Corporation)","Scala Version":"version 2.10.4"},"Spark Properties":{"spark.driver.host":"192.168.230.130","spark.eventLog.enabled":"true","spark.driver.port":"41382","spark.jars":"file:/home/giovanni/applications/two-sources-join/uber-two-sources-join-0.0.1-SNAPSHOT.jar","spark.app.name":"two-sources-join","spark.scheduler.mode":"FIFO","spark.executor.id":"driver","spark.master":"spark://gibbo-virtual:7077","spark.eventLog.dir":"file:///home/giovanni/spark/logs","spark.fileserver.uri":"http://192.168.230.130:45014","spark.externalBlockStore.folderName":"spark-adb51649-eae0-4fc7-98cc-e4723084cc9f","spark.app.id":"app-20150507102911-0001"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.version":"1.7","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Oracle Corporation","java.vm.specification.version":"1.7","user.home":"/home/giovanni","file.encoding.pkg":"sun.io","sun.nio.ch.bugLevel":"","sun.arch.data.model":"64","sun.boot.library.path":"/usr/lib/jvm/java-7-oracle/jre/lib/amd64","user.dir":"/home/giovanni/applications/two-sources-join","java.library.path":"/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib","sun.cpu.isalist":"","os.arch":"amd64","java.vm.version":"24.80-b11","java.endorsed.dirs":"/usr/lib/jvm/java-7-oracle/jre/lib/endorsed","java.runtime.version":"1.7.0_80-b15","java.vm.info":"mixed mode","java.ext.dirs":"/usr/lib/jvm/java-7-oracle/jre/lib/ext:/usr/java/packages/lib/ext","java.runtime.name":"Java(TM) SE Runtime Environment","file.separator":"/","java.class.version":"51.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/usr/lib/jvm/java-7-oracle/jre/lib/resources.jar:/usr/lib/jvm/java-7-oracle/jre/lib/rt.jar:/usr/lib/jvm/java-7-oracle/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-7-oracle/jre/lib/jsse.jar:/usr/lib/jvm/java-7-oracle/jre/lib/jce.jar:/usr/lib/jvm/java-7-oracle/jre/lib/charsets.jar:/usr/lib/jvm/java-7-oracle/jre/lib/jfr.jar:/usr/lib/jvm/java-7-oracle/jre/classes","file.encoding":"UTF-8","user.timezone":"America/New_York","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"3.16.0-36-generic","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Oracle Corporation","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"giovanni","java.vm.name":"Java HotSpot(TM) 64-Bit Server VM","sun.java.command":"org.apache.spark.deploy.SparkSubmit --master spark://gibbo-virtual:7077 --class it.polimi.spark.TwoSourcesJoin uber-two-sources-join-0.0.1-SNAPSHOT.jar -o output -f input1 -s input2","java.home":"/usr/lib/jvm/java-7-oracle/jre","java.version":"1.7.0_80","sun.io.unicode.encoding":"UnicodeLittle"},"Classpath Entries":{"/home/giovanni/git/spark/assembly/target/scala-2.10/spark-assembly-1.4.0-SNAPSHOT-hadoop2.2.0.jar":"System Classpath","/home/giovanni/git/spark/lib_managed/jars/datanucleus-core-3.2.10.jar":"System Classpath","/home/giovanni/git/spark/lib_managed/jars/datanucleus-rdbms-3.2.9.jar":"System Classpath","/home/giovanni/git/spark/lib_managed/jars/datanucleus-api-jdo-3.2.6.jar":"System Classpath","/home/giovanni/git/spark/conf/":"System Classpath","http://192.168.230.130:45014/jars/uber-two-sources-join-0.0.1-SNAPSHOT.jar":"Added By User"}}
{"Event":"SparkListenerApplicationStart","App Name":"two-sources-join","App ID":"app-20150507102911-0001","Timestamp":1431008949326,"User":"giovanni"}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1431008953218,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"mapToPair at TwoSourcesJoin.java:45","Number of Tasks":2,"RDD Info":[{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":5,\"name\":\"map\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"input1","Scope":"{\"id\":0,\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":0,\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.api.java.AbstractJavaRDDLike.mapToPair(JavaRDDLike.scala:47)\nit.polimi.spark.TwoSourcesJoin.main(TwoSourcesJoin.java:45)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:623)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:169)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:192)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:111)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"mapToPair at TwoSourcesJoin.java:54","Number of Tasks":2,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":12,\"name\":\"map\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":3,"Name":"input2","Scope":"{\"id\":7,\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":7,\"name\":\"textFile\"}","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.api.java.AbstractJavaRDDLike.mapToPair(JavaRDDLike.scala:47)\nit.polimi.spark.TwoSourcesJoin.main(TwoSourcesJoin.java:54)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:623)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:169)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:192)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:111)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"saveAsTextFile at TwoSourcesJoin.java:64","Number of Tasks":2,"RDD Info":[{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":22,\"name\":\"saveAsTextFile\"}","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"CoGroupedRDD","Scope":"{\"id\":14,\"name\":\"join\"}","Parent IDs":[2,5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":14,\"name\":\"join\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":14,\"name\":\"join\"}","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[0,1],"Details":"org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:47)\nit.polimi.spark.TwoSourcesJoin.main(TwoSourcesJoin.java:64)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:623)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:169)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:192)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:111)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[0,1,2],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":22,\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"mapToPair at TwoSourcesJoin.java:45","Number of Tasks":2,"RDD Info":[{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":5,\"name\":\"map\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"input1","Scope":"{\"id\":0,\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":0,\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.api.java.AbstractJavaRDDLike.mapToPair(JavaRDDLike.scala:47)\nit.polimi.spark.TwoSourcesJoin.main(TwoSourcesJoin.java:45)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:623)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:169)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:192)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:111)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":22,\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"mapToPair at TwoSourcesJoin.java:54","Number of Tasks":2,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":12,\"name\":\"map\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":3,"Name":"input2","Scope":"{\"id\":7,\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":7,\"name\":\"textFile\"}","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.api.java.AbstractJavaRDDLike.mapToPair(JavaRDDLike.scala:47)\nit.polimi.spark.TwoSourcesJoin.main(TwoSourcesJoin.java:54)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:623)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:169)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:192)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:111)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":22,\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1431008954041,"Executor ID":"0","Executor Info":{"Host":"192.168.230.130","Total Cores":4,"Log Urls":{"stdout":"http://192.168.230.130:8081/logPage/?appId=app-20150507102911-0001&executorId=0&logType=stdout","stderr":"http://192.168.230.130:8081/logPage/?appId=app-20150507102911-0001&executorId=0&logType=stderr"}}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1431008954045,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":1,"Attempt":0,"Launch Time":1431008954060,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1431008954071,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":1,"Attempt":0,"Launch Time":1431008954072,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"192.168.230.130","Port":51469},"Maximum Memory":278302556,"Timestamp":1431008954215}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":1,"Attempt":0,"Launch Time":1431008954060,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1431008956797,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"192.168.230.130","Executor Deserialize Time":1880,"Executor Run Time":551,"Result Size":2009,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":72,"Shuffle Write Time":11679589,"Shuffle Records Written":3},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":12,"Records Read":3}}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1431008954071,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1431008956828,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"192.168.230.130","Executor Deserialize Time":1886,"Executor Run Time":544,"Result Size":2009,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":80,"Shuffle Write Time":40241295,"Shuffle Records Written":4},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":13,"Records Read":4}}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":1,"Attempt":0,"Launch Time":1431008954072,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1431008956828,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"192.168.230.130","Executor Deserialize Time":1884,"Executor Run Time":546,"Result Size":2009,"JVM GC Time":0,"Result Serialization Time":6,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":76,"Shuffle Write Time":40852988,"Shuffle Records Written":3},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":14,"Records Read":3}}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"mapToPair at TwoSourcesJoin.java:54","Number of Tasks":2,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":12,\"name\":\"map\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":3,"Name":"input2","Scope":"{\"id\":7,\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":7,\"name\":\"textFile\"}","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.api.java.AbstractJavaRDDLike.mapToPair(JavaRDDLike.scala:47)\nit.polimi.spark.TwoSourcesJoin.main(TwoSourcesJoin.java:54)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:623)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:169)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:192)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:111)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1431008953394,"Completion Time":1431008956830,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1431008954045,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1431008956833,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"192.168.230.130","Executor Deserialize Time":1887,"Executor Run Time":544,"Result Size":2009,"JVM GC Time":0,"Result Serialization Time":4,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Write Metrics":{"Shuffle Bytes Written":72,"Shuffle Write Time":41458899,"Shuffle Records Written":3},"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":11,"Records Read":3}}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"mapToPair at TwoSourcesJoin.java:45","Number of Tasks":2,"RDD Info":[{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":5,\"name\":\"map\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"input1","Scope":"{\"id\":0,\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":0,\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.api.java.AbstractJavaRDDLike.mapToPair(JavaRDDLike.scala:47)\nit.polimi.spark.TwoSourcesJoin.main(TwoSourcesJoin.java:45)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:623)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:169)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:192)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:111)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1431008953317,"Completion Time":1431008956867,"Accumulables":[]}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"saveAsTextFile at TwoSourcesJoin.java:64","Number of Tasks":2,"RDD Info":[{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":22,\"name\":\"saveAsTextFile\"}","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"CoGroupedRDD","Scope":"{\"id\":14,\"name\":\"join\"}","Parent IDs":[2,5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":14,\"name\":\"join\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":14,\"name\":\"join\"}","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[0,1],"Details":"org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:47)\nit.polimi.spark.TwoSourcesJoin.main(TwoSourcesJoin.java:64)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:623)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:169)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:192)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:111)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":22,\"name\":\"saveAsTextFile\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1431008956997,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":1,"Attempt":0,"Launch Time":1431008956999,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1431008956997,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1431008957367,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"192.168.230.130","Executor Deserialize Time":250,"Executor Run Time":108,"Result Size":892,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":4,"Fetch Wait Time":0,"Remote Bytes Read":0,"Local Bytes Read":140,"Total Records Read":5}}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":1,"Attempt":0,"Launch Time":1431008956999,"Executor ID":"0","Host":"192.168.230.130","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1431008957369,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"192.168.230.130","Executor Deserialize Time":179,"Executor Run Time":177,"Result Size":892,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":4,"Fetch Wait Time":0,"Remote Bytes Read":0,"Local Bytes Read":160,"Total Records Read":8}}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"saveAsTextFile at TwoSourcesJoin.java:64","Number of Tasks":2,"RDD Info":[{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":22,\"name\":\"saveAsTextFile\"}","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"CoGroupedRDD","Scope":"{\"id\":14,\"name\":\"join\"}","Parent IDs":[2,5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":14,\"name\":\"join\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":14,\"name\":\"join\"}","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[0,1],"Details":"org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:47)\nit.polimi.spark.TwoSourcesJoin.main(TwoSourcesJoin.java:64)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:623)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:169)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:192)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:111)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1431008956996,"Completion Time":1431008957370,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1431008957374,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerApplicationEnd","Timestamp":1431008957404}
